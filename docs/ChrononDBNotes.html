<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">.lst-kix_kvvmwy146or2-6>li{counter-increment:lst-ctn-kix_kvvmwy146or2-6}.lst-kix_kvvmwy146or2-3>li{counter-increment:lst-ctn-kix_kvvmwy146or2-3}ol.lst-kix_kvvmwy146or2-5.start{counter-reset:lst-ctn-kix_kvvmwy146or2-5 0}ol.lst-kix_kvvmwy146or2-8{list-style-type:none}ol.lst-kix_kvvmwy146or2-7{list-style-type:none}.lst-kix_kvvmwy146or2-0>li{counter-increment:lst-ctn-kix_kvvmwy146or2-0}.lst-kix_kvvmwy146or2-5>li:before{content:"" counter(lst-ctn-kix_kvvmwy146or2-5,lower-roman) ". "}.lst-kix_kvvmwy146or2-6>li:before{content:"" counter(lst-ctn-kix_kvvmwy146or2-6,decimal) ". "}.lst-kix_kvvmwy146or2-1>li{counter-increment:lst-ctn-kix_kvvmwy146or2-1}ol.lst-kix_kvvmwy146or2-8.start{counter-reset:lst-ctn-kix_kvvmwy146or2-8 0}.lst-kix_kvvmwy146or2-4>li:before{content:"" counter(lst-ctn-kix_kvvmwy146or2-4,lower-latin) ". "}.lst-kix_kvvmwy146or2-7>li{counter-increment:lst-ctn-kix_kvvmwy146or2-7}.lst-kix_kvvmwy146or2-8>li:before{content:"" counter(lst-ctn-kix_kvvmwy146or2-8,lower-roman) ". "}ol.lst-kix_kvvmwy146or2-3.start{counter-reset:lst-ctn-kix_kvvmwy146or2-3 0}ol.lst-kix_kvvmwy146or2-0.start{counter-reset:lst-ctn-kix_kvvmwy146or2-0 0}.lst-kix_kvvmwy146or2-4>li{counter-increment:lst-ctn-kix_kvvmwy146or2-4}.lst-kix_kvvmwy146or2-7>li:before{content:"" counter(lst-ctn-kix_kvvmwy146or2-7,lower-latin) ". "}.lst-kix_kvvmwy146or2-0>li:before{content:"" counter(lst-ctn-kix_kvvmwy146or2-0,decimal) ". "}.lst-kix_kvvmwy146or2-2>li{counter-increment:lst-ctn-kix_kvvmwy146or2-2}ol.lst-kix_kvvmwy146or2-6.start{counter-reset:lst-ctn-kix_kvvmwy146or2-6 0}.lst-kix_kvvmwy146or2-1>li:before{content:"" counter(lst-ctn-kix_kvvmwy146or2-1,lower-latin) ". "}.lst-kix_kvvmwy146or2-2>li:before{content:"" counter(lst-ctn-kix_kvvmwy146or2-2,lower-roman) ". "}.lst-kix_kvvmwy146or2-5>li{counter-increment:lst-ctn-kix_kvvmwy146or2-5}ol.lst-kix_kvvmwy146or2-2.start{counter-reset:lst-ctn-kix_kvvmwy146or2-2 0}.lst-kix_kvvmwy146or2-3>li:before{content:"" counter(lst-ctn-kix_kvvmwy146or2-3,decimal) ". "}.lst-kix_kvvmwy146or2-8>li{counter-increment:lst-ctn-kix_kvvmwy146or2-8}li.li-bullet-0:before{margin-left:-18pt;white-space:nowrap;display:inline-block;min-width:18pt}ol.lst-kix_kvvmwy146or2-0{list-style-type:none}ol.lst-kix_kvvmwy146or2-1.start{counter-reset:lst-ctn-kix_kvvmwy146or2-1 0}ol.lst-kix_kvvmwy146or2-2{list-style-type:none}ol.lst-kix_kvvmwy146or2-1{list-style-type:none}ol.lst-kix_kvvmwy146or2-4{list-style-type:none}ol.lst-kix_kvvmwy146or2-3{list-style-type:none}ol.lst-kix_kvvmwy146or2-7.start{counter-reset:lst-ctn-kix_kvvmwy146or2-7 0}ol.lst-kix_kvvmwy146or2-6{list-style-type:none}ol.lst-kix_kvvmwy146or2-5{list-style-type:none}ol.lst-kix_kvvmwy146or2-4.start{counter-reset:lst-ctn-kix_kvvmwy146or2-4 0}ol{margin:0;padding:0}table td,table th{padding:0}.c1{margin-left:36pt;padding-top:0pt;padding-left:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c5{margin-left:36pt;padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left;height:11pt}.c0{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c8{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c7{margin-left:36pt;padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c6{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left;height:11pt}.c12{padding-top:20pt;padding-bottom:6pt;line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.c14{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:20pt;font-family:"Arial";font-style:normal}.c4{background-color:#ffffff;font-size:9pt;font-family:"Courier New";color:#080808;font-weight:400}.c9{background-color:#ffffff;font-size:9pt;font-family:"Courier New";color:#00627a;font-weight:400}.c3{background-color:#ffffff;font-size:9pt;font-family:"Courier New";color:#0033b3;font-weight:400}.c10{background-color:#ffffff;font-size:9pt;font-family:"Courier New";font-weight:400}.c16{background-color:#ffffff;max-width:468pt;padding:72pt 72pt 72pt 72pt}.c15{text-decoration:none;vertical-align:baseline;font-style:normal}.c2{padding:0;margin:0}.c11{font-style:italic}.c13{color:#871094}.c17{font-weight:700}.title{padding-top:0pt;color:#000000;font-size:26pt;padding-bottom:3pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:0pt;color:#666666;font-size:15pt;padding-bottom:16pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Arial"}p{margin:0;color:#000000;font-size:11pt;font-family:"Arial"}h1{padding-top:20pt;color:#000000;font-size:20pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:18pt;color:#000000;font-size:16pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:16pt;color:#434343;font-size:14pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:14pt;color:#666666;font-size:12pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}</style></head><body class="c16"><h1 class="c12" id="h.9v1kd2six43z"><span class="c14">Assumptions, trade-offs and decisions made</span></h1><p class="c6"><span class="c0"></span></p><ol class="c2 lst-kix_kvvmwy146or2-0 start" start="1"><li class="c1 li-bullet-0"><span class="c0">We are implementing Time Series Data Storage, log is divided into blocks, each block contains some amount of milliseconds (buckets)</span></li></ol><p class="c5"><span class="c0"></span></p><ol class="c2 lst-kix_kvvmwy146or2-0" start="2"><li class="c1 li-bullet-0"><span class="c0">Log is append only</span></li></ol><p class="c5"><span class="c0"></span></p><ol class="c2 lst-kix_kvvmwy146or2-0" start="3"><li class="c1 li-bullet-0"><span class="c0">Individual records can be deleted immediately OR just marked and later collected. I CAN NOT make informed decision, &lsquo;cause mark is faster for DELETE, but will slow down READ. If you have intensive READ - then delete immediately is better. If READ ops are relatively rare, then mark is better.</span></li></ol><p class="c5"><span class="c0"></span></p><ol class="c2 lst-kix_kvvmwy146or2-0" start="4"><li class="c1 li-bullet-0"><span class="c0">TTL is considered as a way to mark records as deleted. </span></li></ol><p class="c5"><span class="c0"></span></p><ol class="c2 lst-kix_kvvmwy146or2-0" start="5"><li class="c1 li-bullet-0"><span class="c0">Deleted records should be removed by the background daemon process (sweeper) which can be triggered manually. I&rsquo;ll write compaction logic, but not daemon. Tests will run vacuum() from time to time.</span></li></ol><p class="c5"><span class="c0"></span></p><ol class="c2 lst-kix_kvvmwy146or2-0" start="6"><li class="c1 li-bullet-0"><span class="c0">Sweeper will also remove dead blocks</span></li></ol><p class="c5"><span class="c0"></span></p><ol class="c2 lst-kix_kvvmwy146or2-0" start="7"><li class="c1 li-bullet-0"><span class="c0">Optimization to mark a block with max TTL value to speed up VACUUM will not be implemented. We need a separate &ldquo;archive&rdquo; process to calculate stats of the block which is no longer current. I&rsquo;m not going to implement this, but this is a useful optimization. If somebody will implement it as a straight field update at the time of WRITEs to the current block - this will slow down WRITE and this is not the best way.</span></li></ol><p class="c5"><span class="c0"></span></p><ol class="c2 lst-kix_kvvmwy146or2-0" start="8"><li class="c1 li-bullet-0"><span class="c0">Same for any block-level counters on how many records added/deleted and is block empty. No enough info to make an informed decision. But this is a trade-off between slower WRITE to current block and slow VACUUM on non-current blocks. If you have a lot of data, long sessions and few WRITE ops, this can be useful.</span></li></ol><p class="c5"><span class="c0"></span></p><ol class="c2 lst-kix_kvvmwy146or2-0" start="9"><li class="c1 li-bullet-0"><span class="c0">No events ordering in the same millisecond to achieve a bit of performance. If events came in some order in the same millisec, this order will not be preserved on read. &nbsp;Reason: functionality doesn&rsquo;t need it and WRITE will be faster just a bit. Nevertheless, if you want to preserve and order, well, use 3rd party concurrent linked hashmap.</span></li></ol><p class="c5"><span class="c0"></span></p><ol class="c2 lst-kix_kvvmwy146or2-0" start="10"><li class="c1 li-bullet-0"><span class="c0">FLUSH is not an atomic operation. If READ is reading data, there is a chance that some flushed records from active uncomplete FLUSH command will be excluded and some included. I can make it atomic by implementing a lock which will stop READ operations (hell, NO!!!) or multiversioning (but this is not a 4 hours even for design)</span></li></ol><p class="c5"><span class="c0"></span></p><ol class="c2 lst-kix_kvvmwy146or2-0" start="11"><li class="c1 li-bullet-0"><span class="c0">Ordering of DELETE commands is not preserved for active READ commands especially if they touch items from the same millisecond bucket. &nbsp;If you have an active long READ command and DELETE A then DELETE B in parallel, you may have a situation when B is present in results and A is not or vice versa. I don&rsquo;t see any reason to implement a fix for this, but if needed - multiversioning is the best way to achieve SERIALIZABLE transaction isolation level</span></li></ol><p class="c5"><span class="c0"></span></p><ol class="c2 lst-kix_kvvmwy146or2-0" start="12"><li class="c1 li-bullet-0"><span class="c0">READ will be slower on sparse data layout, so VACUUM is important. </span></li></ol><p class="c5"><span class="c0"></span></p><ol class="c2 lst-kix_kvvmwy146or2-0" start="13"><li class="c1 li-bullet-0"><span class="c0">Don&rsquo;t forget that we have compactification at the block level only. Block itself can be almost empty and this will slow down READ. The nightmare scenario is a bunch of blocks with a single long-living record in each of them. So, choose block size wise as well as TTL</span></li></ol><p class="c5"><span class="c0"></span></p><ol class="c2 lst-kix_kvvmwy146or2-0" start="14"><li class="c1 li-bullet-0"><span class="c0">Blocks are chained to speed-up search of the next non-empty block. Also we have a block index (block id : block reference) to find a first block of a READ range. Block Index is a simple ConcurrentHashMap, so the initial search is a bunch of map.get() to find the first existing block. </span></li></ol><p class="c5"><span class="c0"></span></p><p class="c7"><span class="c0">I have a little optimization with minKnownBlock to avoid searching for blocks which are gone, so if READ asks for blocks 88-999999 most of which no longer exist, search will start looking from Math.max(minKnownBlock, requestStartBlock).</span></p><p class="c5"><span class="c0"></span></p><p class="c7"><span class="c0">I don&rsquo;t like this approach and I believe we should think about some more advanced tree-like index, which will be able to support floor() and ceil() to find the first available block after a given number.</span></p><p class="c5"><span class="c0"></span></p><ol class="c2 lst-kix_kvvmwy146or2-0" start="15"><li class="c1 li-bullet-0"><span class="c0">VACUUM will not impact any READ operations even when it removes the blocks from index or chain. If long READ got the reference to the block which was deleted from index and chain, reference to the next block will be active and available till READ will be completed and only then GC will remove the block. So, &ldquo;God bless GC architecture&rdquo;.<br><br>Nevertheless, any attempts to clean-up or render invalid or corrupt in any way the block at any time will ruin everything. Even vacuumed block MUST be valid. Don&rsquo;t forget that the block which was vacuumed can be still referenced by long READ operations. </span></li></ol><p class="c5"><span class="c0"></span></p><ol class="c2 lst-kix_kvvmwy146or2-0" start="16"><li class="c1 li-bullet-0"><span class="c0">We have an index (and this is a potential weak spot) of items for DELETE and GET command (item : millisecond registered). It is a ConcurrentHashMap. This index imposes some size limitations (2B records and serious demand to RAM) which can be partially solved by offheap storage AND proper partitioning at the cluster level.</span></li></ol><p class="c5"><span class="c0"></span></p><ol class="c2 lst-kix_kvvmwy146or2-0" start="17"><li class="c1 li-bullet-0"><span class="c0">TTL filter out is guaranteed to be consistent. If READ took 10ms from 100 to 110ms of absolute time, records which had TTL 101, 102, 103, 110 will be ALL excluded or ALL included based on timings.</span></li></ol><p class="c5"><span class="c0"></span></p><ol class="c2 lst-kix_kvvmwy146or2-0" start="18"><li class="c1 li-bullet-0"><span>There is a potential caveat which may render the system inoperable - significant process scheduler fault. Let&rsquo;s imagine that we have a WRITE operation which is delayed in the middle of operation for some reason. Now we have a GHOST record, which was half-registered but never fully written to an index/block.<br><br>If DELETE will come - we are doomed. The only way to fix it is to use a queue for WRITE/DELETE ops + dead-letter-queue for unsuccessful DELETE ops.<br><br>But anyway, we have a situation when a block with a GHOST record is VACUUMed. <br><br>Potentially, we may try to register a record in a block first, but this will NOT resolve the situation completely, the weak point is the place when we chose a block to write and then hanged.<br><br>The best way to avoid such a situation is to implement a locking mechanism which will not impact WRITE/DELETE but will stop VACUUM until all the operations complete. Read/Write lock is good. WRITE operation MUST poll a target block number until lock acquired. This is 100% reliable solution.<br><br>Nevertheless, one more mechanism MUST be added &lsquo;cause it may greatly reduce the problem - delay before block can be VACUUMed and this delta must be at least 500ms + blocksize in ms. My recommendation is to keep up to 1-10 minutes of a blocks. In this case we will let GHOSTs to complete in a reasonable time. This mechanism WILL NOT prevent data loss for GHOSTs, but will reduce the risk significantly.<br><br>For the reliable solution we must use the proper locking mechanism described above I&rsquo;m not going to implement.<br><br></span><span class="c8">WARNING: As I explained, there is a chance to lose the data if WRITE ops will be on hang until proper locking mechanism will be implemented to stop VACUUM of blocks which still have a dead WRITE on them which is NOT properly registered.</span></li></ol><p class="c5"><span class="c0"></span></p><ol class="c2 lst-kix_kvvmwy146or2-0" start="19"><li class="c1 li-bullet-0"><span class="c0">We may have a TTL in the item index to clean-up dead records, nevertheless I would prefer to let VACUUM clean-up this index. Anyway, coherence between data and indexes is always somewhat a pain. This is a question to discuss and the choice will rely on the data I need.</span></li></ol><p class="c5"><span class="c0"></span></p><ol class="c2 lst-kix_kvvmwy146or2-0" start="20"><li class="c1 li-bullet-0"><span class="c0">Variable block size is not supported, but can be considered in the future.</span></li></ol><p class="c6"><span class="c0"></span></p><ol class="c2 lst-kix_kvvmwy146or2-0" start="21"><li class="c1 li-bullet-0"><span class="c0">Properties must be immutable, especially block size for now. So, I added comment but added some capability to refactor code in a future to dynamic properties and block size</span></li></ol><p class="c5"><span class="c0"></span></p><ol class="c2 lst-kix_kvvmwy146or2-0" start="22"><li class="c1 li-bullet-0"><span class="c0">The whole implementation is built around two principles <br><br>1) only buckets are mutable and we have ConcurrentHashMap to handle concurrency <br><br>2) Data structures and algos designed in a way that if change happened in another thread, this will not affect threads currently active. This reduced the need for synchronization dramatically.<br><br>For example, if a block was vacuumed, the reader or writer, who already picked up it&rsquo;s reference, is still able to read/write it and jump to the next block. We have a GC, so I&rsquo;m heavily relying on it, leaving deleted blocks integrated and consistent. GC is extremely important for my logic, &lsquo;cause, actually, I have a 2-stage vacuuming process and GC is used as a thread&rsquo;s references tracker and kinda trash bin.<br><br>If this code will be implemented on C++, then GC-like logic should be introduced to free memory on this 2nd stage.</span></li></ol><p class="c5"><span class="c0"></span></p><ol class="c2 lst-kix_kvvmwy146or2-0" start="23"><li class="c1 li-bullet-0"><span>Algorithm designed in a way that FLUSH will not erase records which are added after the FLUSH command was issued with 1ms accuracy. Data which arrived the </span><span class="c17">same</span><span class="c0">&nbsp;millisecond as FLUSH was issued are not guaranteed to be protected, but code is written in a way that minimizes the chance to erase data added the same ms, but after the FLUSH command. <br><br>Look, this is concurrency and we don&rsquo;t provide strong commands ordering. If we want really strong ordering, we will need to have the command queue.<br><br>So, if FLUSH (1, 2000) was issued at the time 100ms and then record A was added at the time 101ms, FLUSH (1, 2000) will not affect A even if it will work from 100 to 300ms.<br><br>But if FLUSH(1,2000) and then ADD will be issued the same millisecond, algorithm will try to minimize the chance that FLUSH will erase ADD.<br><br>If you don&rsquo;t like it - remove commandTime restrictions.<br></span></li><li class="c1 li-bullet-0"><span class="c0">Very similar approach is used for GET. Algorithm will try to return data no later than timm command time with 1ms precision.<br><br>If you don&rsquo;t like it - remove commandTime restrictions.</span></li></ol><p class="c5"><span class="c0"></span></p><ol class="c2 lst-kix_kvvmwy146or2-0" start="25"><li class="c1 li-bullet-0"><span>There are no restrictions for GET on records count or execution time. I would propose to limit this or create and API with limitations in rows or milliseconds, something like </span><span class="c9">get</span><span class="c4">(</span><span class="c3">long </span><span class="c4">startTimeMillis, </span><span class="c3">long </span><span class="c4">endTimeMillis, </span><span class="c3">int </span><span class="c4 c15">rowLimit)</span></li></ol><p class="c7"><span class="c0">or</span></p><p class="c7"><span class="c9">get</span><span class="c4">(</span><span class="c3">long </span><span class="c4">startTimeMillis, </span><span class="c3">long </span><span class="c4">endTimeMillis, </span><span class="c3">int </span><span class="c4">querySoftLimitMs)</span></p><p class="c5"><span class="c0"></span></p><ol class="c2 lst-kix_kvvmwy146or2-0" start="26"><li class="c1 li-bullet-0"><span class="c0">GET may clean-up buckets from expired elements, this may slow down first GET a bit, but speed up following GETs. VACUUM, actually, do this also.<br><br>If you don&rsquo;t like this approach, see LogBlock.get() and remove bucket update and index update.<br><br>But if you&rsquo;ll ask me, I&rsquo;d propose to<br>1. Let GET trigger VACUUM in separate thread, based on statistics gathered<br>2. Let GET do clean-up to some extent, like no more than 25% of rows or no more than 10ms<br><br>Anyway, this is a long discussion. Let&rsquo;s have it!</span></li></ol><p class="c5"><span class="c0"></span></p><ol class="c2 lst-kix_kvvmwy146or2-0" start="27"><li class="c1 li-bullet-0"><span class="c0">ADD may return an exception if the process hangs under the load, this is intentional. It would be better to return an exception, rather than hang indefinitely. <br><br>So, if ADD can not get a lock for block rotation for more than 100ms or ADD is unable to complete write in time to a newly rotated block (1000ms) then the method throws an exception.<br><br>Such exceptions must be ultimately considered as a request to decrease speed and retry later (exponential delays must be used or DLQ). Also cluster scaler must start immediate dynamic scaling UP.</span></li></ol><p class="c5"><span class="c0"></span></p><ol class="c2 lst-kix_kvvmwy146or2-0" start="28"><li class="c1 li-bullet-0"><span class="c0">Some code, like Log.add() can look strange because of duplicated code. This is intentional to save some time in a hotplate. The idea is that the happy path is jet fast and if we need to rotate the block, then we will add more checks.</span></li></ol><p class="c5"><span class="c0"></span></p><ol class="c2 lst-kix_kvvmwy146or2-0" start="29"><li class="c1 li-bullet-0"><span>I expect that FLUSH is a rare operation, so FLUSH actually scratches the data out from buckets and index. So, FLUSH is slow, but GET is fast. If FLUSH is used frequently, we will need obsoleteBucketsLog which will be honored by GET and will be a task queue for VACUUM. <br></span><span class="c3">this</span><span class="c4">.obsoleteBucketsLog = </span><span class="c10">ConcurrentHashMap</span><span class="c4">.</span><span class="c4 c11">newKeySet</span><span class="c4">(</span><span class="c10 c13">blockSize</span><span class="c4 c15">);</span></li><li class="c1 li-bullet-0"><span class="c0">Static block size</span></li></ol><p class="c5"><span class="c0"></span></p><ol class="c2 lst-kix_kvvmwy146or2-0" start="31"><li class="c1 li-bullet-0"><span class="c0">Unique itemId. Can be fixed with advanced Items Index or PUT should delete old one</span></li></ol><p class="c5"><span class="c0"></span></p><ol class="c2 lst-kix_kvvmwy146or2-0" start="32"><li class="c1 li-bullet-0"><span class="c0">Get is not consistent on TTL, VACUUM can run in background and remove some TTL-outdated items</span></li></ol><p class="c5"><span class="c0"></span></p><ol class="c2 lst-kix_kvvmwy146or2-0" start="33"><li class="c1 li-bullet-0"><span class="c0">Vacuum is not parallel and not time bound</span></li></ol><p class="c5"><span class="c0"></span></p><p class="c5"><span class="c0"></span></p><p class="c6"><span class="c0"></span></p></body></html>